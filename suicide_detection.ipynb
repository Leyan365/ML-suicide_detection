{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de2a25d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9319a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Am I weird I don't get affected by compliments...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>I’m so lostHello, my name is Adam (16) and I’v...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class\n",
       "0           2  Ex Wife Threatening SuicideRecently I left my ...      suicide\n",
       "1           3  Am I weird I don't get affected by compliments...  non-suicide\n",
       "2           4  Finally 2020 is almost over... So I can never ...  non-suicide\n",
       "3           8          i need helpjust help me im crying so hard      suicide\n",
       "4           9  I’m so lostHello, my name is Adam (16) and I’v...      suicide"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Suicide_Detection.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5aca2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232074 entries, 0 to 232073\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  232074 non-null  int64 \n",
      " 1   text        232074 non-null  object\n",
      " 2   class       232074 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5c8b681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6bf78dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "suicide        116037\n",
       "non-suicide    116037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a29485b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['text']       # features\n",
    "y = df['class']      # target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85a01a6",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c21f0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import neattext.functions as nfx\n",
    "\n",
    "def clean_text(text_series):\n",
    "    text_length = []\n",
    "    cleaned_text = []\n",
    "\n",
    "    for sent in tqdm(text_series):\n",
    "        sent = sent.lower()\n",
    "        sent = nfx.remove_special_characters(sent)\n",
    "        sent = nfx.remove_stopwords(sent)\n",
    "        text_length.append(len(sent.split()))\n",
    "        cleaned_text.append(sent)\n",
    "    \n",
    "    return cleaned_text, text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "829ca495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/185659 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185659/185659 [00:20<00:00, 8906.08it/s]\n",
      "100%|██████████| 46415/46415 [00:05<00:00, 8757.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# Clean the training text\n",
    "X_train_cleaned, X_train_length = clean_text(X_train)\n",
    "\n",
    "# Clean the test text\n",
    "X_test_cleaned, X_test_length = clean_text(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5f4738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70121789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text to squences of integers\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_cleaned)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_cleaned)\n",
    "    \n",
    "# pad sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=100, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=100, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c2468d",
   "metadata": {},
   "source": [
    "### Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b2e5388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbl_target = LabelEncoder()\n",
    "train_output = lbl_target.fit_transform(y_train)\n",
    "test_output = lbl_target.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe35ebdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['non-suicide' 'suicide']\n"
     ]
    }
   ],
   "source": [
    "print(lbl_target.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38e271ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 85471/271463 words (31.49%)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load GloVe pickle\n",
    "with open('glove.840B.300d.pkl', 'rb') as fp:\n",
    "    glove_embedding = pickle.load(fp)\n",
    "\n",
    "# Build embedding matrix\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "embedding_dim = 300\n",
    "embedding_matrix = np.zeros((vocab_size + 1, embedding_dim), dtype=float)\n",
    "\n",
    "found = 0\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    embedding_vector = glove_embedding.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[idx] = embedding_vector\n",
    "        found += 1\n",
    "\n",
    "print(f\"Found embeddings for {found}/{vocab_size} words ({found/vocab_size:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2eca9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stop = EarlyStopping(patience = 5)\n",
    "reducelr = ReduceLROnPlateau(patience = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f700b",
   "metadata": {},
   "source": [
    "### Keras Sequential Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11a269c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 300)          81439200  \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100, 20)           25680     \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 20)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               5376      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,470,513\n",
      "Trainable params: 31,313\n",
      "Non-trainable params: 81,439,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(\n",
    "    input_dim=vocab_size + 1,\n",
    "    output_dim=embedding_dim,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=100,       \n",
    "    trainable=False\n",
    "))\n",
    "model.add(LSTM(20, return_sequences=True))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile\n",
    "optimizer = SGD(learning_rate=0.1, momentum=0.09)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42daf5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "726/726 [==============================] - 110s 145ms/step - loss: 0.3456 - accuracy: 0.8514 - val_loss: 0.3005 - val_accuracy: 0.8748 - lr: 0.1000\n",
      "Epoch 2/10\n",
      "726/726 [==============================] - 63s 87ms/step - loss: 0.2179 - accuracy: 0.9152 - val_loss: 0.3181 - val_accuracy: 0.8669 - lr: 0.1000\n",
      "Epoch 3/10\n",
      "726/726 [==============================] - 64s 89ms/step - loss: 0.1754 - accuracy: 0.9326 - val_loss: 0.1821 - val_accuracy: 0.9291 - lr: 0.1000\n",
      "Epoch 4/10\n",
      "726/726 [==============================] - 65s 89ms/step - loss: 0.1537 - accuracy: 0.9416 - val_loss: 0.1941 - val_accuracy: 0.9231 - lr: 0.1000\n",
      "Epoch 5/10\n",
      "726/726 [==============================] - 62s 86ms/step - loss: 0.1438 - accuracy: 0.9456 - val_loss: 0.3395 - val_accuracy: 0.8704 - lr: 0.1000\n",
      "Epoch 6/10\n",
      "726/726 [==============================] - 63s 87ms/step - loss: 0.1368 - accuracy: 0.9482 - val_loss: 0.1746 - val_accuracy: 0.9304 - lr: 0.1000\n",
      "Epoch 7/10\n",
      "726/726 [==============================] - 61s 85ms/step - loss: 0.1312 - accuracy: 0.9508 - val_loss: 0.1769 - val_accuracy: 0.9311 - lr: 0.1000\n",
      "Epoch 8/10\n",
      "726/726 [==============================] - 61s 85ms/step - loss: 0.1278 - accuracy: 0.9520 - val_loss: 0.2035 - val_accuracy: 0.9215 - lr: 0.1000\n",
      "Epoch 9/10\n",
      "726/726 [==============================] - 62s 86ms/step - loss: 0.1244 - accuracy: 0.9534 - val_loss: 0.1817 - val_accuracy: 0.9288 - lr: 0.1000\n",
      "Epoch 10/10\n",
      "726/726 [==============================] - 69s 95ms/step - loss: 0.1179 - accuracy: 0.9559 - val_loss: 0.1849 - val_accuracy: 0.9286 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train_pad,\n",
    "    train_output,\n",
    "    validation_data=(X_test_pad, test_output),\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stop, reducelr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c6a14",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "170ef300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1451/1451 [==============================] - 25s 17ms/step - loss: 0.1849 - accuracy: 0.9286\n",
      "Test Accuracy: 92.86%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test_pad, test_output)\n",
    "print(f\"Test Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3ec2615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1451/1451 [==============================] - 24s 16ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-suicide       0.90      0.96      0.93     23208\n",
      "     suicide       0.96      0.90      0.93     23207\n",
      "\n",
      "    accuracy                           0.93     46415\n",
      "   macro avg       0.93      0.93      0.93     46415\n",
      "weighted avg       0.93      0.93      0.93     46415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = (model.predict(X_test_pad) > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(test_output, y_pred, target_names=lbl_target.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f997b1c",
   "metadata": {},
   "source": [
    "### Functions to make Predictions on New Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a51e1481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_suicide(text):\n",
    "    cleaned = nfx.remove_special_characters(text.lower())\n",
    "    cleaned = nfx.remove_stopwords(cleaned)\n",
    "    seq = tokenizer.texts_to_sequences([cleaned])\n",
    "    pad = pad_sequences(seq, maxlen=100, padding='post')\n",
    "    pred = model.predict(pad)[0][0]\n",
    "    label = lbl_target.inverse_transform([int(pred > 0.5)])[0]\n",
    "    print(f\"Prediction: {label} ({pred:.2f} confidence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90fe6a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "Prediction: suicide (0.93 confidence)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prediction: suicide (0.86 confidence)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Prediction: non-suicide (0.23 confidence)\n"
     ]
    }
   ],
   "source": [
    "predict_suicide(\"I don't want to live anymore.\")\n",
    "predict_suicide(\"I feel hopeless and tired of everything.\")\n",
    "predict_suicide(\"Life is going great, I’m excited for tomorrow!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34be5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model.save(\"suicide_detection_lstm_glove.h5\")\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lbl_target, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
